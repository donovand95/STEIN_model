{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ER_import(stoch_base_ER):\n",
    "    read_in = open(r'C:/Users/dennis/Documents/STEIN_links/for_publication/model_outputs/stochastic_erosion/erosion_sets/import_dates.csv')\n",
    "    myreader = csv.reader(read_in)\n",
    "    \n",
    "    for row in myreader:\n",
    "        mat_gen_dates = row[:]\n",
    "    \n",
    "    ERs = np.genfromtxt(r'C:/Users/dennis/Documents/STEIN_links/for_publication/model_outputs/stochastic_erosion/erosion_sets/ER_list_' + str(stoch_base_ER) + '_' + str(mat_gen_dates[-1]) + '.csv',\n",
    "                                  delimiter = ',')\n",
    "        \n",
    "    return ERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def CN_stoch_in_fxn(ERs_all):\n",
    "    CN_import = np.empty((total_time, 4, scenarios))\n",
    "    for i in range(scenarios):\n",
    "        CN_import[:,:3,i] = np.genfromtxt(r'C:/Users/dennis/Documents/STEIN_links/for_publication/model_outputs/stochastic_erosion/Be10_C14_simulation_outputs/STO_C14_Be10_ER' + str(ERs_all[i]) + '_expmat.csv', \n",
    "                                          delimiter = ',')\n",
    "\n",
    "        CN_import[:,3,i] = np.genfromtxt('C:/Users/dennis/Documents/STEIN_links/for_publication/model_outputs/stochastic_erosion/He3_simulation_outputs/STO_He3_ER' + str(ERs_all[i]) + '_surfmat.csv',\n",
    "                              delimiter = ',')\n",
    "        \n",
    "    return CN_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def sampling_fxn(CN_import_matrix, sample_no, scenarios):\n",
    "    P0_Be10 = SLHL_Be10 * scaling_factor\n",
    "    P0_He3 = SLHL_Be10 * scaling_factor\n",
    "    sampling_years = np.sort(np.random.choice(np.arange(int(total_time * 0.1),total_time),sample_no))\n",
    "    sampling_mat = np.empty((sample_no, 6, scenarios))\n",
    "    measured = np.empty((6,scenarios))\n",
    "    \n",
    "    for j in range(scenarios):\n",
    "        \n",
    "        sampling_14C = []\n",
    "        sampling_Be = []\n",
    "        sampling_rat = []\n",
    "        sampling_3He = []\n",
    "    \n",
    "        for i in range(sample_no):           \n",
    "\n",
    "            sampling_14C.append(CN_import_matrix[sampling_years[i],0,j])\n",
    "            sampling_Be.append(CN_import_matrix[sampling_years[i],1,j])\n",
    "            sampling_rat.append(CN_import_matrix[sampling_years[i],2,j])\n",
    "            sampling_3He.append(CN_import_matrix[sampling_years[i],3,j])\n",
    "        \n",
    "        sampling_mat[:,0,j] = sampling_14C\n",
    "        sampling_mat[:,1,j] = sampling_Be\n",
    "        sampling_mat[:,2,j] = sampling_rat\n",
    "        sampling_mat[:,3,j] = sampling_3He\n",
    "        sampling_mat[:,4,j] = np.divide(sampling_3He,sampling_Be) * (P0_Be10 / P0_He3)\n",
    "        sampling_mat[:,5,j] = sampling_years\n",
    "        \n",
    "        \n",
    "        measured[0,j] = np.mean(sampling_mat[:,0,j])\n",
    "        measured[1,j] = np.mean(sampling_mat[:,1,j])\n",
    "        measured[2,j] = measured[0,j] / measured[1,j]\n",
    "        measured[3,j] = np.mean(sampling_mat[:,3,j])\n",
    "        measured[4,j] = (np.mean(sampling_mat[:,4,j]) / np.mean(sampling_mat[:,1])) * (P0_Be10 / P0_He3)\n",
    "        measured[5,j] = (160 / 2.62 * P0_Be10 / measured[1,j])\n",
    "    \n",
    "    measured_ER = [(160 / 2.62 * P0_Be10 / measured[1,j]) for j in range(scenarios)]\n",
    "    \n",
    "    return sampling_mat, measured, measured_ER  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_constant_comps(measured_ER):\n",
    "    %run C:/Users/dennis/Documents/STEIN_links/for_publication/CRN_comparison_outputs_generator.ipynb\n",
    "    %run C:/Users/dennis/Documents/STEIN_links/for_publication/He3_comparison_outputs_generator.ipynb\n",
    "    \n",
    "    comp_mat = np.empty((total_time, 5, scenarios))\n",
    "    \n",
    "    shift_ER = False\n",
    "    save_only_surf = True\n",
    "    save_output = True    \n",
    "    \n",
    "    for i in range(scenarios):\n",
    "        \n",
    "        initial_ER = measured_ER[i]\n",
    "        comp_mat[:,2,i], comp_mat[:,0,i], comp_mat[:,1,i] = CRN_comp_loop_fxn(total_time, initial_ER)[2:5] \n",
    "        comp_mat[:,3,i] = He3_comp_loop_fxn(total_time, initial_ER)\n",
    "        comp_mat[:,4,i] = np.divide(comp_mat[:,3,i], comp_mat[:,1,i]) * (P0_Be10 / P0_He3)\n",
    "        \n",
    "    return comp_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def original_ER_fxn(ERs_all):\n",
    "    %run C:/Users/dennis/Documents/STEIN_links/for_publication/CRN_comparison_outputs_generator.ipynb\n",
    "    %run C:/Users/dennis/Documents/STEIN_links/for_publication/He3_comparison_outputs_generator.ipynb\n",
    "\n",
    "    og_ER_mat = np.empty((total_time, 5, scenarios))\n",
    "    \n",
    "    shift_ER = False\n",
    "    save_only_surf = True\n",
    "    save_output = True    \n",
    "        \n",
    "    for i in range(scenarios):\n",
    "        initial_ER = ERs_all[i]\n",
    "        og_ER_mat[:,2,i], og_ER_mat[:,0,i], og_ER_mat[:,1,i] = CRN_comp_loop_fxn(total_time, initial_ER)[2:5] \n",
    "        og_ER_mat[:,3,i] = He3_comp_loop_fxn(total_time, initial_ER)\n",
    "        og_ER_mat[:,4,i] = np.divide(og_ER_mat[:,3,i], og_ER_mat[:,1,i]) * (P0_Be10 / P0_He3)\n",
    "        \n",
    "    return og_ER_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compare_fxn():\n",
    "    \n",
    "    ERs_all = ER_import(stoch_base_ER)\n",
    "    CN_import = CN_stoch_in_fxn(ERs_all)\n",
    "    samples, measured, measured_ER = sampling_fxn(CN_import, sample_no, scenarios)\n",
    "    const_comp_mat = generate_constant_comps(measured_ER)\n",
    "    \n",
    "    return const_comp_mat, samples, measured, measured_ER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
